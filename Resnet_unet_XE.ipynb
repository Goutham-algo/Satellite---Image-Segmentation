{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1514093,
          "sourceType": "datasetVersion",
          "datasetId": 892049
        }
      ],
      "dockerImageVersionId": 30528,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-12-08T10:16:16.780304Z",
          "iopub.execute_input": "2023-12-08T10:16:16.781029Z",
          "iopub.status.idle": "2023-12-08T10:16:16.785893Z",
          "shell.execute_reply.started": "2023-12-08T10:16:16.780993Z",
          "shell.execute_reply": "2023-12-08T10:16:16.784872Z"
        },
        "trusted": true,
        "id": "h2YkMFJgNHT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "\n",
        "def increase_brightness(input_path, output_path, brightness_factor):\n",
        "    # Open the image file\n",
        "    with Image.open(input_path) as img:\n",
        "        # Enhance the brightness\n",
        "        enhancer = ImageEnhance.Brightness(img)\n",
        "        brightened_img = enhancer.enhance(brightness_factor)\n",
        "\n",
        "        # Save the brightened image\n",
        "        brightened_img.save(output_path)\n"
      ],
      "metadata": {
        "id": "_v2vBNgKNHUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in images:\n",
        "    input_image_path = \"massachusetts-buildings-dataset/png/train/\"+i\n",
        "\n",
        "    # Specify the output directory for the brightened image\n",
        "    output_directory = \"Sample\"\n",
        "\n",
        "    # Ensure the output directory exists\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    # Specify the brightness factor (1.0 is unchanged, values greater than 1 increase brightness)\n",
        "    brightness_factor = 1.5\n",
        "\n",
        "    # Generate the output file path by combining the output directory and input image filename\n",
        "    input_filename = os.path.basename(input_image_path)\n",
        "    output_image_path = os.path.join(output_directory, f\"{input_filename}\")\n",
        "\n",
        "    # Increase brightness and save the image\n",
        "    increase_brightness(input_image_path, output_image_path, brightness_factor)"
      ],
      "metadata": {
        "id": "uXkYykGvNHUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "\n",
        "# Specify the paths to the original images and masks\n",
        "original_images_path = 'brightned'\n",
        "mask_images_path = 'massachusetts-buildings-dataset/png/train_labels'\n",
        "\n",
        "# Specify the output directory for the augmented images and masks\n",
        "output_images_path = 'train_1'\n",
        "output_masks_path = 'masks_1'\n",
        "\n",
        "# Specify the new output location\n",
        "new_output_images_path = 'train_images'\n",
        "new_output_masks_path = 'train_masks'\n",
        "\n",
        "# Create output directories if they don't exist\n",
        "os.makedirs(new_output_images_path, exist_ok=True)\n",
        "os.makedirs(new_output_masks_path, exist_ok=True)\n",
        "\n",
        "# Function to apply random transformations\n",
        "def apply_random_transformations(image, mask):\n",
        "    # Randomly choose whether to apply transformations\n",
        "    if np.random.rand() > 0.5:\n",
        "        # Apply Gaussian filter\n",
        "        sigma = np.random.uniform(0.5, 2.0)\n",
        "        image = cv2.GaussianBlur(image, (0, 0), sigma)\n",
        "\n",
        "    if np.random.rand() > 0.5:\n",
        "        # Apply 90-degree rotation\n",
        "        image = np.rot90(image)\n",
        "        mask = np.rot90(mask)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "# Desired number of augmented images\n",
        "target_num_images = 250\n",
        "\n",
        "# Counter for the number of augmented images created\n",
        "num_created_images = 0\n",
        "\n",
        "# Iterate until the desired number of images is reached\n",
        "while num_created_images < target_num_images:\n",
        "    # Iterate over each original image\n",
        "    for filename in os.listdir(original_images_path):\n",
        "        if filename.endswith('.png'):  # Adjust the extension based on your image format\n",
        "            # Load original image and corresponding mask\n",
        "            image_path = os.path.join(original_images_path, filename)\n",
        "            mask_path = os.path.join(mask_images_path, filename)\n",
        "\n",
        "            original_image = io.imread(image_path)\n",
        "            mask_image = io.imread(mask_path)\n",
        "\n",
        "            # Apply random transformations\n",
        "            augmented_image, augmented_mask = apply_random_transformations(original_image, mask_image)\n",
        "\n",
        "            # Save augmented images and masks to the new output location\n",
        "            new_output_image_path = os.path.join(new_output_images_path, f\"{num_created_images}_{filename}\")\n",
        "            new_output_mask_path = os.path.join(new_output_masks_path, f\"{num_created_images}_{filename}\")\n",
        "\n",
        "            io.imsave(new_output_image_path, augmented_image)\n",
        "            io.imsave(new_output_mask_path, augmented_mask)\n",
        "\n",
        "            num_created_images += 1\n",
        "\n",
        "            # Break the loop if the desired number of images is reached\n",
        "            if num_created_images == target_num_images:\n",
        "                break\n",
        "\n",
        "# Now, you have generated and saved 250 augmented images and masks in the specified directories.\n"
      ],
      "metadata": {
        "id": "3xBQ-occNHUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'massachusetts-buildings-dataset/png'\n",
        "images_dir ='train_images'\n",
        "masks_dir = 'train_masks'\n",
        "val_images_dir ='massachusetts-buildings-dataset/png/val'\n",
        "val_masks_dir = 'massachusetts-buildings-dataset/png/val_labels'\n",
        "test_images_dir='massachusetts-buildings-dataset/png/test'\n",
        "test_masks_dir='massachusetts-buildings-dataset/png/test_labels'\n",
        "images_listdir = os.listdir(images_dir)\n",
        "masks_listdir = os.listdir(masks_dir)\n",
        "random_images = np.random.choice(masks_listdir, size = 9, replace = False)\n",
        "test_images_listdir = os.listdir(test_images_dir)\n",
        "test_masks_listdir = os.listdir(test_masks_dir)\n",
        "image_size= 224\n",
        "input_image_size=(1500,1500)\n",
        "def read_image(path):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.resize(img, (image_size, image_size))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "number= 250\n",
        "rows = 3\n",
        "cols = 3\n",
        "fig, ax = plt.subplots(rows, cols, figsize = (10,10))\n",
        "for i, ax in enumerate(ax.flat):\n",
        "    if i < len(random_images):\n",
        "        img = read_image(f\"{images_dir}/{random_images[i]}\")\n",
        "        ax.set_title(f\"{random_images[i]}\")\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "fig, ax = plt.subplots(rows, cols, figsize = (10,10))\n",
        "for i, ax in enumerate(ax.flat):\n",
        "    if i < len(random_images):\n",
        "        file=random_images[i]\n",
        "        if os.path.exists(os.path.join(masks_dir,file)):\n",
        "            img = read_image(f\"{masks_dir}/{file}\")\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            ax.set_title(f\"{random_images[i]}\")\n",
        "            ax.imshow(img)\n",
        "            ax.axis('off')\n",
        "        else:\n",
        "            print('not exist')\n",
        "\n",
        "MASKS=np.zeros((1,image_size, image_size, 1), dtype=bool)\n",
        "IMAGES=np.zeros((1,image_size, image_size, 3),dtype=np.uint8)\n",
        "\n",
        "for j,file in enumerate(masks_listdir[0:number]):   ##the smaller, the faster\n",
        "    try:\n",
        "        image = read_image(f\"{images_dir}/{file}\")\n",
        "        image_ex = np.expand_dims(image, axis=0)\n",
        "        IMAGES = np.vstack([IMAGES, image_ex])\n",
        "        file2=file[0:-4]+'.png'\n",
        "        mask = read_image(f\"{masks_dir}/{file2}\")\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        mask = mask.reshape(image_size,image_size,1)\n",
        "        mask_ex = np.expand_dims(mask, axis=0)\n",
        "        MASKS = np.vstack([MASKS, mask_ex])\n",
        "    except:\n",
        "        print(file)\n",
        "        continue\n",
        "TMASKS=np.zeros((1,image_size, image_size,1), dtype=bool)\n",
        "TIMAGES=np.zeros((1,image_size, image_size,3),dtype=np.uint8)\n",
        "\n",
        "for j,file in enumerate(test_images_listdir): ##the smaller, the faster\n",
        "    try:\n",
        "        image = read_image(f\"{test_images_dir}/{file}\")\n",
        "        image_ex = np.expand_dims(image, axis=0)\n",
        "        TIMAGES = np.vstack([TIMAGES, image_ex])\n",
        "        file2=file[0:-4]+'.png'\n",
        "        mask = read_image(f\"{test_masks_dir}/{file2}\")\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        mask = mask.reshape(image_size,image_size,1)\n",
        "        mask_ex = np.expand_dims(mask, axis=0)\n",
        "        TMASKS = np.vstack([TMASKS, mask_ex])\n",
        "    except:\n",
        "        print(file)\n",
        "        continue\n",
        "images=np.array(IMAGES)[1:number+1]\n",
        "masks=np.array(MASKS)[1:number+1]\n",
        "test_images=np.array(TIMAGES)[1:]\n",
        "test_masks=np.array(TMASKS[1:])\n",
        "images_train, images_test, masks_train, masks_test = train_test_split(images, masks, test_size=0.2, random_state=43)\n",
        "\n",
        "print(images_train.shape)\n",
        "print(images_test.shape)\n",
        "images_train = images_train/255.0\n",
        "images_val = images_test/255.0\n",
        "masks_train =  masks_train/255.0\n",
        "masks_val = masks_test/255.0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T11:29:36.471268Z",
          "iopub.execute_input": "2023-12-08T11:29:36.471947Z",
          "iopub.status.idle": "2023-12-08T11:30:05.968334Z",
          "shell.execute_reply.started": "2023-12-08T11:29:36.471915Z",
          "shell.execute_reply": "2023-12-08T11:30:05.967377Z"
        },
        "trusted": true,
        "id": "sLJwKA0kNHUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def squeeze_excite_block(tensor,ratio=16):\n",
        "    init = tensor\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    filters = init.shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='relu', kernel_initializer='he_normal', use_bias=True)(se)\n",
        "    se = Dense(filters, activation='relu', kernel_initializer='he_normal', use_bias=True)(se)\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        se = Permute((3, 1, 2))(se)\n",
        "    x = multiply([init, se],name='squeeze_and_excitation')\n",
        "    return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T11:30:05.970228Z",
          "iopub.execute_input": "2023-12-08T11:30:05.970830Z",
          "iopub.status.idle": "2023-12-08T11:30:05.980264Z",
          "shell.execute_reply.started": "2023-12-08T11:30:05.970796Z",
          "shell.execute_reply": "2023-12-08T11:30:05.979156Z"
        },
        "trusted": true,
        "id": "-jwOD1GcNHUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input,Dropout,GlobalAveragePooling2D,Reshape,Dense,Permute,multiply\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_resnet50_unet(input_shape):\n",
        "\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "\n",
        "    resnet50 = ResNet50(include_top=False,input_tensor=inputs)\n",
        "    resnet50.trainable = True\n",
        "\n",
        "\n",
        "    s1 = resnet50.get_layer(\"input_15\").output  ## (224 x 224)\n",
        "    s2 = resnet50.get_layer(\"conv1_relu\").output        ## (112 x 112)\n",
        "    s3 = resnet50.get_layer(\"conv2_block3_out\").output  ## (56 x 56)\n",
        "    s4 = resnet50.get_layer(\"conv3_block4_out\").output  ## (28 x 28)\n",
        "\n",
        "\n",
        "    b1 = resnet50.get_layer(\"conv4_block6_out\").output  ## (14 x 14)\n",
        "\n",
        "    d1 = decoder_block(squeeze_excite_block(b1), s4, 512) #(28 x 28)\n",
        "    d2 = decoder_block(d1, s3, 256)                     ## (56 x 56)\n",
        "    d3 = decoder_block(d2, s2, 128)                     ## (112 x 112)\n",
        "    d4 = decoder_block(d3, s1, 64)                      ##(224 x 224)\n",
        "\n",
        "    \"\"\" Output \"\"\"\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"ResNet50_U-Net-XE\")\n",
        "\n",
        "    return model,b1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_shape = (224, 224, 3)\n",
        "    model,b1 = build_resnet50_unet(input_shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T11:37:14.722490Z",
          "iopub.execute_input": "2023-12-08T11:37:14.723497Z",
          "iopub.status.idle": "2023-12-08T11:37:16.782430Z",
          "shell.execute_reply.started": "2023-12-08T11:37:14.723460Z",
          "shell.execute_reply": "2023-12-08T11:37:16.781384Z"
        },
        "trusted": true,
        "id": "qt2LuTa5NHUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "learning_rate = 0.001  # Adjust the value based on your specific task and observations\n",
        "\n",
        "# Initialize the Adam optimizer with the specified learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss')\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model1.h5\", monitor='val_loss', save_best_only=True)\n",
        "\n",
        "#,validation_data = [test_pre,masks_pre_test],shuffle=True,steps_per_epoch=3\n",
        "\n",
        "history = model.fit(images_train,masks_train,epochs = 100,callbacks=[checkpoint],validation_data=[images_val,masks_val])"
      ],
      "metadata": {
        "id": "GTjLPhbRNHUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is the object returned by model.fit()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(12, 6))  # Adjust the figure size if needed\n",
        "plt.subplot(1, 2, 1)  # Creating a subplot for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 2)  # Creating a subplot for accuracy\n",
        "plt.plot(history.history['accuracy'])  # Assuming 'accuracy' is the training accuracy\n",
        "plt.plot(history.history['val_accuracy'])  # Assuming 'val_accuracy' is the validation accuracy\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()  # Adjust layout to prevent clipping\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-08T10:11:17.397252Z",
          "iopub.execute_input": "2023-12-08T10:11:17.398108Z",
          "iopub.status.idle": "2023-12-08T10:11:17.892557Z",
          "shell.execute_reply.started": "2023-12-08T10:11:17.398072Z",
          "shell.execute_reply": "2023-12-08T10:11:17.891657Z"
        },
        "trusted": true,
        "id": "MyNAgbEZNHUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "  # Replace with the path to your saved model\n",
        "\n",
        "# Load a new image for prediction\n",
        "img_path = 'Sample/23428960_15.png'  # Replace with the path to your new image\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = img_array/255.0\n",
        "# Perform prediction\n",
        "predictions = best_model.predict(img_array)\n",
        "\n",
        "# Assuming your model outputs segmentation masks, you might want to threshold the predictions\n",
        "threshold = 0.5  # Adjust as needed\n",
        "predicted_mask = (predictions>threshold).astype(np.uint8)\n",
        "\n",
        "# Visualize the original image, predicted mask, and overlay\n",
        "original_image = image.load_img(img_path)\n",
        "original_image_array = image.img_to_array(original_image) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "  # Adjust the target size to match your model's input size\n",
        "\n",
        "\n",
        "# Plot original image\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original_image_array)\n",
        "plt.title('Original Image')\n",
        "\n",
        "# Plot predicted mask\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(predicted_mask[0, :, :, 0], cmap='gray')  # Assuming a single-channel mask\n",
        "plt.title('Predicted Mask')\n",
        "\n",
        "# Plot overlay\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(original_image_array)\n",
        "plt.imshow(predictions[0, :, :, 0], cmap='gray', alpha=0.5)  # Adjust the colormap as needed\n",
        "plt.title('Overlay')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o99sbTLcNHUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}